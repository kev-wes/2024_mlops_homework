{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to familiarize users with monitoring for ML batch services, using PostgreSQL database to store metrics and Grafana to visualize them.\n",
    "\n",
    "\n",
    "\n",
    "## Q1. Prepare the dataset\n",
    "\n",
    "Start with `baseline_model_nyc_taxi_data.ipynb`. Download the March 2024 Green Taxi data. We will use this data to simulate a production usage of a taxi trip duration prediction service.\n",
    "\n",
    "What is the shape of the downloaded data? How many rows are there?\n",
    "\n",
    "* 72044\n",
    "* 78537 \n",
    "* 57457\n",
    "* 54396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57457"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. !conda create -n 05-monitoring-2023 python=3.11\n",
    "# 2. !conda activate 05-monitoring-2023\n",
    "# 3. Move to project folder 'cd 2024_mlops_homework/05-monitoring/2024'\n",
    "# 4. !pip install -r requirements.txt\n",
    "# 5. Move to data folder 'cd 2024_mlops_homework/05-monitoring/2024/data'\n",
    "# 6. !wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-03.parquet\n",
    "\n",
    "import pandas as pd\n",
    "mar_df = pd.read_parquet('data/green_tripdata_2024-03.parquet')\n",
    "mar_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Metric\n",
    "\n",
    "Let's expand the number of data quality metrics we’d like to monitor! Please add one metric of your choice and a quantile value for the `\"fare_amount\"` column (`quantile=0.5`).\n",
    "\n",
    "Hint: explore evidently metric `ColumnQuantileMetric` (from `evidently.metrics import ColumnQuantileMetric`) \n",
    "\n",
    "What metric did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Open https://docs.evidentlyai.com/reference/all-metrics\n",
    "# 2. Go to https://docs.evidentlyai.com/reference/all-metrics#data-quality\n",
    "# 3. Pick any metric\n",
    "# --> DatasetCorrelationsMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Monitoring\n",
    "\n",
    "Let’s start monitoring. Run expanded monitoring for a new batch of data (March 2024). \n",
    "\n",
    "What is the maximum value of metric `quantile = 0.5` on the `\"fare_amount\"` column during March 2024 (calculated daily)?\n",
    "\n",
    "* 10\n",
    "* 12.5\n",
    "* 14.2\n",
    "* 14.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum daily quantile: 14.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnQuantileMetric\n",
    "\n",
    "data = pd.read_parquet('data/green_tripdata_2024-03.parquet')\n",
    "\n",
    "# create target\n",
    "data[\"duration_min\"] = data.lpep_dropoff_datetime - data.lpep_pickup_datetime\n",
    "data.duration_min = data.duration_min.apply(lambda td : float(td.total_seconds())/60)\n",
    "\n",
    "# filter out outliers\n",
    "data = data[(data.duration_min >= 0) & (data.duration_min <= 60)]\n",
    "data = data[(data.passenger_count > 0) & (data.passenger_count <= 8)]\n",
    "# Compute the daily quantiles and find the maximum quantile\n",
    "data['date'] = data['lpep_pickup_datetime'].dt.date  # Extract date from datetime\n",
    "\n",
    "# data labeling\n",
    "num_features = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"total_amount\"]\n",
    "cat_features = [\"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    target=None,\n",
    "    prediction=None,\n",
    "    numerical_features=num_features,\n",
    "    categorical_features=cat_features\n",
    ")\n",
    "\n",
    "report = Report(metrics=[\n",
    "    ColumnQuantileMetric(column_name='fare_amount', quantile=0.5)\n",
    "]\n",
    ")\n",
    "\n",
    "# Initialize a list to store daily quantiles\n",
    "daily_quantiles = []\n",
    "\n",
    "for i in range (1,31):\n",
    "    report.run(reference_data=None, current_data=data.loc[data.lpep_pickup_datetime.between(f'2024-03-{i:02}', f'2024-03-{i+1:02}', inclusive=\"left\")], column_mapping=column_mapping)\n",
    "    result = report.as_dict()\n",
    "    quantile = result['metrics'][0]['result']['current']['value']\n",
    "    daily_quantiles.append(quantile)\n",
    "\n",
    "# Find the maximum daily quantile\n",
    "max_daily_quantile = max(daily_quantiles)\n",
    "print(f\"Maximum daily quantile: {max_daily_quantile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AS THE NEXT QUESTION IS ALREADY ABOUT GRAFANA, I WANTED TO ONLY USE EVIDENTLY UI HERE\n",
    " \n",
    "from evidently.metric_preset import DataQualityPreset\n",
    "\n",
    "from evidently.ui.workspace import Workspace\n",
    "from evidently.ui.dashboards import DashboardPanelCounter, DashboardPanelPlot, CounterAgg, PanelValue, PlotType, ReportFilter\n",
    "from evidently.renderers.html_widgets import WidgetSize\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "\n",
    "\n",
    "val_data = pd.read_parquet('data/green_tripdata_2022-01.parquet')\n",
    "\n",
    "# create target\n",
    "val_data[\"duration_min\"] = val_data.lpep_dropoff_datetime - val_data.lpep_pickup_datetime\n",
    "val_data.duration_min = val_data.duration_min.apply(lambda td : float(td.total_seconds())/60)\n",
    "\n",
    "# filter out outliers\n",
    "val_data = val_data[(val_data.duration_min >= 0) & (val_data.duration_min <= 60)]\n",
    "val_data = val_data[(val_data.passenger_count > 0) & (val_data.passenger_count <= 8)]\n",
    "\n",
    "# data labeling\n",
    "target = \"duration_min\"\n",
    "num_features = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"total_amount\"]\n",
    "cat_features = [\"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "ws = Workspace(\"workspace\")\n",
    "\n",
    "project = ws.create_project(\"NYC Taxi Data Quality Project\")\n",
    "project.description = \"My project description\"\n",
    "project.save()\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    target=None,\n",
    "    prediction=None,\n",
    "    numerical_features=num_features,\n",
    "    categorical_features=cat_features\n",
    ")\n",
    "\n",
    "regular_report = Report(\n",
    "    metrics=[\n",
    "        DataQualityPreset()\n",
    "    ],\n",
    "    timestamp=datetime.datetime(2022,1,28)\n",
    ")\n",
    "\n",
    "regular_report.run(reference_data=None,\n",
    "                  current_data=val_data.loc[val_data.lpep_pickup_datetime.between('2022-01-28', '2022-01-29', inclusive=\"left\")],\n",
    "                  column_mapping=column_mapping)\n",
    "\n",
    "ws.add_report(project.id, regular_report)\n",
    "\n",
    "#configure the dashboard\n",
    "project.dashboard.add_panel(\n",
    "    DashboardPanelCounter(\n",
    "        filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "        agg=CounterAgg.NONE,\n",
    "        title=\"NYC taxi data dashboard\"\n",
    "    )\n",
    ")\n",
    "\n",
    "project.dashboard.add_panel(\n",
    "    DashboardPanelPlot(\n",
    "        filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "        title=\"Inference Count\",\n",
    "        values=[\n",
    "            PanelValue(\n",
    "                metric_id=\"DatasetSummaryMetric\",\n",
    "                field_path=\"current.number_of_rows\",\n",
    "                legend=\"count\"\n",
    "            ),\n",
    "        ],\n",
    "        plot_type=PlotType.BAR,\n",
    "        size=WidgetSize.HALF,\n",
    "    ),\n",
    ")\n",
    "\n",
    "project.dashboard.add_panel(\n",
    "    DashboardPanelPlot(\n",
    "        filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "        title=\"Number of Missing Values\",\n",
    "        values=[\n",
    "            PanelValue(\n",
    "                metric_id=\"DatasetSummaryMetric\",\n",
    "                field_path=\"current.number_of_missing_values\",\n",
    "                legend=\"count\"\n",
    "            ),\n",
    "        ],\n",
    "        plot_type=PlotType.LINE,\n",
    "        size=WidgetSize.HALF,\n",
    "    ),\n",
    ")\n",
    "\n",
    "project.save()\n",
    "\n",
    "regular_report = Report(\n",
    "    metrics=[\n",
    "        DataQualityPreset()\n",
    "    ],\n",
    "    timestamp=datetime.datetime(2022,1,29)\n",
    ")\n",
    "\n",
    "regular_report.run(reference_data=None,\n",
    "                  current_data=val_data.loc[val_data.lpep_pickup_datetime.between('2022-01-29', '2022-01-30', inclusive=\"left\")],\n",
    "                  column_mapping=column_mapping)\n",
    "\n",
    "ws.add_report(project.id, regular_report)\n",
    "\n",
    "# 1. Start UI with 'evidently ui'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Dashboard\n",
    "\n",
    "\n",
    "Finally, let’s add panels with new added metrics to the dashboard. After we customize the  dashboard let's save a dashboard config, so that we can access it later. Hint: click on “Save dashboard” to access JSON configuration of the dashboard. This configuration should be saved locally.\n",
    "\n",
    "Where to place a dashboard config file?\n",
    "\n",
    "* `project_folder` (05-monitoring)\n",
    "* `project_folder/config`  (05-monitoring/config)\n",
    "* `project_folder/dashboards`  (05-monitoring/dashboards)\n",
    "* `project_folder/data`  (05-monitoring/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> project_folder/dashboards (05-monitoring/dashboards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FOR CAPSTONE PROJECT\n",
    "- Problem with Evidently UI is that data is stored in data snapshots (JSON files)\n",
    "- That is why PostgreSQL + Grafana is used in lecture\n",
    "- What to do in project?\n",
    "    - Schedule monitoring batch job and send regular emails using prefect?\n",
    "    - Use only evidently code and not PostgreSQL & Grafana?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9518218744f0b9b1ad0428c8736ef0dab9d4af0755264adb654350f464e3c0eb"
  },
  "kernelspec": {
   "display_name": "Python 3.11.9 ('05-monitoring-2024': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
